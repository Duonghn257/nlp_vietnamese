{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150c3ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "from src.dataset import VietnameseTextDataset, prepare_vietnamese_dataset, load_texts_from_folder\n",
    "from tokenizers import Tokenizer\n",
    "import torch\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Punctuation, Sequence, Digits, Metaspace\n",
    "from tokenizers.normalizers import NFC, NFD, Sequence as NormalizerSequence\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "import os\n",
    "import glob\n",
    "from src.tokenizer import VietnameseTokenizer, VietnamesePreprocessor\n",
    "\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53058e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"vietnamese_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd046dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = VietnamesePreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f18c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = load_texts_from_folder(\"data/clean_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c27e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "for text in raw_texts:\n",
    "    cleaned_text = preprocessor.clean_text(text)\n",
    "    sentences_from_file = preprocessor.segment_sentences(cleaned_text)\n",
    "    all_sentences.extend(\n",
    "        sentences_from_file\n",
    "    )  # Use extend to add all sentences to one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081f3aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171188\n"
     ]
    }
   ],
   "source": [
    "print(len(all_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7295e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 171714 training sequences\n"
     ]
    }
   ],
   "source": [
    "train_dataset = VietnameseTextDataset(all_sentences, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b341d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    item = train_dataset[i]\n",
    "    # print(i, item['input_ids'].shape)\n",
    "    if item['input_ids'].shape[0] > 512:\n",
    "        print(\"Too long:\", item['input_ids'].shape[0])\n",
    "        print(\"Text: \", tokenizer.decode(item['input_ids'].tolist(), skip_special_tokens=True).replace(\" ##\", \"\"))\n",
    "    # if i > 20:  # just to avoid printing all\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea222f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e90924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fcda7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a9126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "823d0269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "thơ lục bát : \n",
      " Việt nam con cháu lạc hồng \n",
      " Phải học thuộc lòng trang sử đã qua \n",
      " Nhớ công lao của ông cha \n",
      " Đổ bao xương máu cho ta yên bình \n",
      " Thắng mười bốn cuộc trường chinh \n",
      " Giữ toàn vẹn tổ quốc mình hôm nay \n",
      " Trên từng tấc đất ngấm đầy \n",
      " Máu và nước mắt bao ngày con ơi \n",
      " Trải qua mười bốn cuộc rồi \n",
      " Giặc phương bắc đã nối đời đánh ta \n",
      " Từ ngày khai quốc rất xa \n",
      " Đến tư chính mới hôm qua rất gần \n",
      " Một là quân giặc nhà ân \n",
      " Tràn sang cướp bóc bắt dân xây đồn \n",
      " Khắp kinh thành đến xóm thôn \n",
      " Tiếng kêu thấu đất oan hồn lạc bay \n",
      " Vua sai sứ giả bao ngày \n",
      " Đi tìm người giỏi về ngay kinh thành \n",
      " Để trao ngựa kiếm một thanh \n",
      " Chàng trai phù đổng hoá thành thiên vương \n",
      " Tướng quân nhận lệnh lên đường \n",
      " Dẫn binh thẳng đến chiến trường xông pha \n",
      " Qua vài trận đấu với ta \n",
      " Ân vương đã chết thành ma không đầu \n",
      " Truyện còn kể đến mai sau \n",
      " Dựng xây đất nước dài lâu vững bền \n",
      " Đó là năm trước công nguyên \n",
      " Một hai một tám lưu truyền sử xanh \n",
      " Hai là trong cuộc chiến tranh \n",
      " Nhà tần hung hãn cũng đành chịu thua \n",
      " Vua tần đâu phải loại vừa \n",
      " Trung hoa bá chủ vẫn chưa hài lòng \n",
      " Trung nguyên vừa mới dẹp xong \n",
      " Điều ngay binh tướng xuôi dòng trường giang \n",
      " Âm mưu chiếm đất phương nam \n",
      " An dương vương đã đánh tan giặc tần \n",
      " Ba là giặc hán đảo điên \n",
      " Chiếm phương nam muốn đánh liền rút nhanh \n",
      " May thay trời giúp dân lành \n",
      " Giặc lây dịch bệnh hoành hành khắp nơi \n",
      " Quân xâm lược trái ý trời \n",
      " Không quen thời tiết thổ ngơi chết nhiều \n",
      " Tướng quân chu táo liêu xiêu \n",
      " Vào năm một tám một liều lui binh \n",
      " Tư là năm chẵn bốn mươi \n",
      " Hai bà trưng vốn là người mê linh \n",
      " Đứng lên dấy nghĩa khởi binh \n",
      " Đánh tan đông hán tự mình lên ngôi \n",
      " Giặc phương bắc quét sạch rồi \n",
      " Ba năm gánh vác mệnh trời với dân \n",
      " Đến khi mã viện dồn quân \n",
      " Tìm dòng sông hát trẫm thân dưới cầu \n",
      " Năm là ở cõi giao châu \n",
      " Có quan lý bí quê đầu long hưng \n",
      " Đánh quân lương thắng lẫy lừng \n",
      " Năm trăm bốn mốt tưng bừng cờ hoa \n",
      " Lên ngôi vua lấy hiệu là \n",
      " Lý nam đế lập nước nhà vạn xuân \n",
      " Duy trì được đến bẩy năm \n",
      " Vua đầu tiên của việt nam sử vàng \n",
      " Sáu là trên bạch đằng giang \n",
      " Chín trăm ba tám tiếng vang nức lòng \n",
      " Ngô quyền cắm cọc giữa sông \n",
      " Cho thuyền nam hán chìm không lối về \n",
      " Lưu hoằng tháo nhục ê chề \n",
      " Tướng thua chết lính khó bề thoát thân \n",
      " Ngô quyền thắng trận thu quân \n",
      " Tái sinh đất nước toàn dân vui vầy \n",
      " Bẩy là hoàng đế nhà đinh \n",
      " Cùng con bị giết triều đình lung lay \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset.__getitem__(386)\n",
    "\n",
    "ids = sample['input_ids']\n",
    "print(len(ids))\n",
    "print(tokenizer.decode(ids.tolist(), skip_special_tokens=False).replace(\" ##\", \"\").replace(\"_\", \" \").replace(\"[LF]\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a34dfe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n",
      "825\n",
      "860\n",
      "2596\n",
      "2766\n",
      "4253\n",
      "4660\n",
      "4937\n",
      "5250\n",
      "5421\n",
      "5526\n",
      "6171\n",
      "9052\n",
      "9527\n",
      "10408\n",
      "11075\n",
      "11513\n",
      "12092\n",
      "12203\n",
      "12519\n",
      "13989\n",
      "14157\n",
      "15127\n",
      "15177\n",
      "15200\n",
      "15900\n",
      "16027\n",
      "16358\n",
      "16429\n",
      "17162\n",
      "18303\n",
      "18855\n",
      "19024\n",
      "19095\n",
      "20017\n",
      "21930\n",
      "22109\n",
      "23547\n",
      "23883\n",
      "24937\n",
      "25251\n",
      "25308\n",
      "27407\n",
      "27475\n",
      "28628\n",
      "29127\n",
      "31129\n",
      "31145\n",
      "31271\n",
      "31574\n",
      "31789\n",
      "32552\n",
      "33386\n",
      "33731\n",
      "33798\n",
      "34911\n",
      "36549\n",
      "37793\n",
      "37915\n",
      "39099\n",
      "39102\n",
      "39115\n",
      "40134\n",
      "40961\n",
      "43037\n",
      "43718\n",
      "44400\n",
      "45438\n",
      "45561\n",
      "48095\n",
      "48721\n",
      "49711\n",
      "50134\n",
      "50500\n",
      "50729\n",
      "51580\n",
      "52022\n",
      "52202\n",
      "53673\n",
      "54480\n",
      "54580\n",
      "54616\n",
      "54823\n",
      "55005\n",
      "55484\n",
      "55973\n",
      "57157\n",
      "57477\n",
      "57759\n",
      "57794\n",
      "58209\n",
      "58371\n",
      "58514\n",
      "58902\n",
      "60165\n",
      "60290\n",
      "60766\n",
      "61345\n",
      "61447\n",
      "61786\n",
      "62733\n",
      "63651\n",
      "63655\n",
      "63759\n",
      "66437\n",
      "66500\n",
      "67453\n",
      "69051\n",
      "69889\n",
      "69936\n",
      "71712\n",
      "72069\n",
      "72124\n",
      "73104\n",
      "73160\n",
      "74127\n",
      "74142\n",
      "74203\n",
      "77685\n",
      "78967\n",
      "80192\n",
      "80632\n",
      "81472\n",
      "82812\n",
      "82884\n",
      "86154\n",
      "86331\n",
      "87079\n",
      "87147\n",
      "87296\n",
      "87367\n",
      "87460\n",
      "87762\n",
      "88241\n",
      "89205\n",
      "90789\n",
      "91831\n",
      "92785\n",
      "94308\n",
      "94977\n",
      "96852\n",
      "101262\n",
      "101751\n",
      "104249\n",
      "105842\n",
      "108097\n",
      "108825\n",
      "109226\n",
      "110669\n",
      "111942\n",
      "112663\n",
      "113276\n",
      "116029\n",
      "116287\n",
      "116460\n",
      "122679\n",
      "123419\n",
      "124441\n",
      "124713\n",
      "124988\n",
      "125234\n",
      "125372\n",
      "125390\n",
      "125625\n",
      "125675\n",
      "126411\n",
      "126431\n",
      "126446\n",
      "127217\n",
      "127230\n",
      "127558\n",
      "127598\n",
      "128457\n",
      "129232\n",
      "129392\n",
      "129857\n",
      "129872\n",
      "130357\n",
      "130455\n",
      "130965\n",
      "131113\n",
      "131237\n",
      "132201\n",
      "132413\n",
      "133094\n",
      "133281\n",
      "133482\n",
      "133969\n",
      "134057\n",
      "134250\n",
      "135905\n",
      "136317\n",
      "136673\n",
      "137142\n",
      "137490\n",
      "137647\n",
      "137909\n",
      "138359\n",
      "139310\n",
      "139509\n",
      "140096\n",
      "140165\n",
      "141147\n",
      "141179\n",
      "141315\n",
      "141364\n",
      "142012\n",
      "143243\n",
      "144157\n",
      "144653\n",
      "144808\n",
      "145221\n",
      "145468\n",
      "145539\n",
      "145593\n",
      "145617\n",
      "145649\n",
      "146145\n",
      "146413\n",
      "146821\n",
      "147094\n",
      "147495\n",
      "147741\n",
      "147781\n",
      "148413\n",
      "148421\n",
      "148962\n",
      "149439\n",
      "150124\n",
      "150470\n",
      "150876\n",
      "151081\n",
      "151344\n",
      "152332\n",
      "152515\n",
      "152540\n",
      "152610\n",
      "152903\n",
      "152958\n",
      "153176\n",
      "153268\n",
      "154436\n",
      "154657\n",
      "155484\n",
      "155819\n",
      "156945\n",
      "157116\n",
      "157383\n",
      "158337\n",
      "158528\n",
      "158975\n",
      "160088\n",
      "160727\n",
      "160765\n",
      "161002\n",
      "161156\n",
      "161469\n",
      "161486\n",
      "161492\n",
      "161535\n",
      "161731\n",
      "162358\n",
      "162807\n",
      "164393\n",
      "165168\n",
      "165430\n",
      "165547\n",
      "166300\n",
      "167014\n",
      "167048\n",
      "167935\n",
      "168483\n",
      "169389\n",
      "169530\n",
      "170256\n",
      "170595\n",
      "171087\n",
      "171298\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    if train_dataset[i][\"input_ids\"].tolist()[-1] != 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = prepare_vietnamese_dataset(\"data/clean_data\", tokenizer=tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505aaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    if batch['input_ids'].shape[1] > 512:\n",
    "        print(batch['input_ids'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3be1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
